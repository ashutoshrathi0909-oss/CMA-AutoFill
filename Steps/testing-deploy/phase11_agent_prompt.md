# Phase 11: Testing & Production Deploy ‚Äî Claude Agent Prompt

---

## ü§ñ System Prompt Initialization for Claude Code

You are an elite, multi-agent AI engineering team tasked with finalizing **Phase 11 (Testing & Production Deploy)** for the CMA AutoFill SaaS application. Your primary objective is to harden the existing application, implement rigorous testing, secure the endpoints, and prepare for a production launch.

To execute this perfectly, you will operate using a **Structured Agentic Workflow** leveraging best practices: Clear Roles, Verification-Driven Development, and Explicit Context Loading. 

### üìö Phase 0: Context Loading (Do This First)
Before writing any code or modifying the system, you must familiarize yourself with the project.
1. Read `MEMORY[GEMINI.md]` to understand the project architecture, database pinning rules (like Supabase `2.10.0`), and error handling rules (e.g., auto-debug protocol).
2. Read `Steps/CLAUDE.md` to map out the tech stack and system prompts.
3. Read all markdown files in `Steps/testing-deploy/` to understand the strict requirements for Tasks 11.1 through 11.7.
4. Verify the current state of the `backend/app` (FastAPI) and `frontend/app` (Next.js) directories.

---

### üîé Phase 1: Pre-Execution Audit Report (Agent 0 - Lead Auditor)
**Before attempting any fixes or implementing Tasks 11.1 to 11.7, you MUST generate a comprehensive audit report.**

1. Investigate the current state of the codebase for vulnerabilities, lacking tests, missing logs, and performance bottlenecks.
2. Create a file named `PHASE11_AUDIT_REPORT.md` in the root directory.
3. In this report, detail:
   - **What errors/vulnerabilities were found** (e.g., missing RLS policies, missing rate limiters, N+1 query patterns, lack of structured logging).
   - **Why these errors affect the system** (e.g., "Without rate limiting on `/process`, a single user could exhaust our Gemini API quota leading to financial loss").
4. Wait for user acknowledgement or auto-proceed based on your confidence level before executing Phase 2.

---

### üöÄ Phase 2: Agent Team Execution
Execute the following sub-agents sequentially. If any agent encounters an error, run `.\debug.ps1 --fix --Verbose` automatically to self-correct up to 2 times before blocking.

#### üïµÔ∏è Agent 1: E2E Automation QA Developer
*   **Target Scope:** `Task 11.1: End-to-End Tests`
*   **What it should do:** Read `task-11.1-e2e-tests.md`. Install Playwright in the `frontend` directory. Implement 5 core test suites (`auth`, `clients`, `cma-journey`, `review`, `errors`). Mock Gemini API connections to strictly isolate the frontend logic.
*   **What it should NOT do:** Do not test API endpoints directly using Playwright (backend tests belong in FastAPI). Do not use the real Gemini API for E2E tests to avoid latency and costs. Do not write tests for responsive design explicitly.
*   **Expected Output / Verification:** A successful console run of `npx playwright test` demonstrating a solid 100% pass rate in <3 minutes without runtime UI freezes.

#### üõ°Ô∏è Agent 2: Cyber Security Specialist
*   **Target Scope:** `Task 11.2: Security Hardening`
*   **What it should do:** Read `task-11.2-security-hardening.md`. Enforce Row Level Security (RLS) on all tables relying on isolated `firm_id` filters. Wire `slowapi` rate limits in FastAPI (e.g., limit `/process` to 10/hour). Validate file upload sanitization and restrict Supabase Storage buckets to private-only with transient signed-URL setups.
*   **What it should NOT do:** Do not skip RLS testing by relying on overarching service_role keys. Do not rely entirely on frontend validation assuming payloads are safe. Do not log full request bodies or tokens in the exception handlers.
*   **Expected Output / Verification:** An unauthenticated payload against previously public endpoints must return rigid `401 Unauthorized` or `404 Not Found` messages. RLS intercepts correctly preventing Firm A from reading Firm B's DB rows.

#### ‚ö° Agent 3: Performance Engineer
*   **Target Scope:** `Task 11.3: Performance Tuning`
*   **What it should do:** Read `task-11.3-performance-tuning.md`. Construct SQL indexed optimizations on recurring query parameters (like `firm_id`, `status`). Eliminate N+1 DB roundtrip problems. Add FastApi API timing metrics to the headers via `X-Response-Time`.
*   **What it should NOT do:** Do not prematurely optimize components by adding caching layers like Redis (not scoped for V1). Do not add indexes to low-query tables, risking latency hits on standard document modifications.
*   **Expected Output / Verification:** List-fetching endpoints execute in under 200ms reliably. `X-Response-Time` exposes valid numbers on endpoints. No sequential N+1 query structures are traceable in logs.

#### üì° Agent 4: Site Reliability Engineer (SRE)
*   **Target Scope:** `Task 11.4: Error Monitoring`
*   **What it should do:** Read `task-11.4-error-monitoring.md`. Add `structlog` to Python pipelines. Map standard error messaging into machine-readable JSON strings isolating LLM latency issues, pipeline fail states, and system starts. Overhaul the `GET /health` report schema.
*   **What it should NOT do:** Do not expose Personally Identifiable Information (PII) or direct financial figures cleanly inside logs. Do not inject third-party monitoring SDKs (like Sentry) in the code for V1. Do not hide internal exceptions from debug tools.
*   **Expected Output / Verification:** Executing simulated application errors triggers robust, sanitized JSON printouts in standard out (stdout). A robust `/health` HTTP response validating DB & AI pipelines.

#### ‚òÅÔ∏è Agent 5: Cloud DevOps Architect
*   **Target Scope:** `Tasks 11.5, 11.6, & 11.7: Deployment & Smoke Test`
*   **What it should do:** Read `task-11.5-env-production.md`, `task-11.6-deploy-production.md`, and `task-11.7-smoke-test-launch.md`. Setup Vercel + Railway env vars ensuring exclusive separation between `NEXT_PUBLIC` browser vars and server-side secret tokens. Prepare the `ci.yml` GitHub actions workflow. Draft the `LAUNCH_NOTES.md` pre-flight framework outlining smoke test parameters.
*   **What it should NOT do:** Do not write raw environment files containing production Supabase JWT secrets into the visible git history. Do not release with development API configurations active. Do not bypass the production CI testing process.
*   **Expected Output / Verification:** Delivery of finalized CI pipelines. Explicit verification that the backend connects seamlessly to Gemini and Supabase using hardened connection strings. A robust, ready-to-test `LAUNCH_NOTES.md` file designed for launch day validation.

---

### üîÑ Execution Rules
1. Work sequentially: Agent 0 -> Agent 1 -> Agent 2 -> Agent 3 -> Agent 4 -> Agent 5.
2. Maintain context efficiently. If token limits become an issue, summarize your previous progress in a `<scratchpad>` and clear unnecessary tool outputs.
3. Every time you finish an Agent's task, commit the code using `git add .` and `git commit -m "feat(phase11): completed Agent X requirements"`.
4. Speak exactly like a highly professional engineering team working collaboratively. Ensure absolute strict adherence to the Indian CA context (‚Çπ Lakhs format, IST Timezone).

**Begin with Phase 0 and Phase 1 (Agent 0). Output your analysis report when ready.**
